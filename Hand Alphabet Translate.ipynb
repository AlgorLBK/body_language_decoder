{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (0.10.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pandas in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: jax in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.25)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: pycparser in c:\\users\\algor lombako\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        #print(results.right_hand_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(' '):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capture Landmarks & Export to CSV\n",
    "<!--<img src=\"https://i.imgur.com/8bForKY.png\">-->\n",
    "<!--<img src=\"https://i.imgur.com/AzKNp7A.png\">-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords = 21 #Hand has 21 landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Y\" # From A to Z to add the landmarks to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks / useless at this point\n",
    "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "         #                        mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "          #                       mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "           #                      )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections / useless at this point\n",
    "        #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "        #                         mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "        #                         mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "        #                         )\n",
    "        # Export coordinates\n",
    "       # try:\n",
    "            # Extract Left and Rigth hand landmarks / one at the time\n",
    "        if results.right_hand_landmarks:\n",
    "            pose = results.right_hand_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            row = pose_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "                \n",
    "           # except:\n",
    "            #    print('no')\n",
    "             #   pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(' '):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z19</th>\n",
       "      <th>v19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>v20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "      <th>v21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>1.014420</td>\n",
       "      <td>-6.802763e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.802850</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>-0.013200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876929</td>\n",
       "      <td>0.847015</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878708</td>\n",
       "      <td>0.875686</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.880794</td>\n",
       "      <td>1.000834</td>\n",
       "      <td>-5.970348e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808890</td>\n",
       "      <td>0.980843</td>\n",
       "      <td>-0.013410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875507</td>\n",
       "      <td>0.838928</td>\n",
       "      <td>-0.011486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881289</td>\n",
       "      <td>0.864441</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.875478</td>\n",
       "      <td>1.000710</td>\n",
       "      <td>-6.209229e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812720</td>\n",
       "      <td>0.981782</td>\n",
       "      <td>-0.017534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887454</td>\n",
       "      <td>0.849501</td>\n",
       "      <td>-0.027056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888212</td>\n",
       "      <td>0.878121</td>\n",
       "      <td>-0.012948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.877295</td>\n",
       "      <td>0.996915</td>\n",
       "      <td>-5.995648e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.810931</td>\n",
       "      <td>0.981167</td>\n",
       "      <td>-0.017814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.885406</td>\n",
       "      <td>0.846887</td>\n",
       "      <td>-0.022345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888111</td>\n",
       "      <td>0.872026</td>\n",
       "      <td>-0.008568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0.870285</td>\n",
       "      <td>0.995014</td>\n",
       "      <td>-6.071867e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805751</td>\n",
       "      <td>0.976099</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879430</td>\n",
       "      <td>0.849899</td>\n",
       "      <td>-0.021579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882398</td>\n",
       "      <td>0.876090</td>\n",
       "      <td>-0.007873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x1        y1            z1   v1        x2        y2        z2  \\\n",
       "0     A  0.872361  1.014420 -6.802763e-07  0.0  0.802850  0.984900 -0.013200   \n",
       "1     A  0.880794  1.000834 -5.970348e-07  0.0  0.808890  0.980843 -0.013410   \n",
       "2     A  0.875478  1.000710 -6.209229e-07  0.0  0.812720  0.981782 -0.017534   \n",
       "3     A  0.877295  0.996915 -5.995648e-07  0.0  0.810931  0.981167 -0.017814   \n",
       "4     A  0.870285  0.995014 -6.071867e-07  0.0  0.805751  0.976099 -0.014567   \n",
       "\n",
       "    v2        x3  ...       z19  v19       x20       y20       z20  v20  \\\n",
       "0  0.0  0.742364  ... -0.032420  0.0  0.876929  0.847015 -0.018758  0.0   \n",
       "1  0.0  0.745570  ... -0.025347  0.0  0.875507  0.838928 -0.011486  0.0   \n",
       "2  0.0  0.750220  ... -0.039444  0.0  0.887454  0.849501 -0.027056  0.0   \n",
       "3  0.0  0.747848  ... -0.035215  0.0  0.885406  0.846887 -0.022345  0.0   \n",
       "4  0.0  0.745917  ... -0.033790  0.0  0.879430  0.849899 -0.021579  0.0   \n",
       "\n",
       "        x21       y21       z21  v21  \n",
       "0  0.878708  0.875686 -0.003740  0.0  \n",
       "1  0.881289  0.864441  0.002510  0.0  \n",
       "2  0.888212  0.878121 -0.012948  0.0  \n",
       "3  0.888111  0.872026 -0.008568  0.0  \n",
       "4  0.882398  0.876090 -0.007873  0.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z19</th>\n",
       "      <th>v19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>v20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "      <th>v21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.301277</td>\n",
       "      <td>0.713866</td>\n",
       "      <td>-4.999960e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376766</td>\n",
       "      <td>0.687557</td>\n",
       "      <td>-0.021483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274309</td>\n",
       "      <td>0.341676</td>\n",
       "      <td>-0.039328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.289744</td>\n",
       "      <td>-0.035333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.300141</td>\n",
       "      <td>0.712820</td>\n",
       "      <td>-4.968692e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376357</td>\n",
       "      <td>0.686942</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274595</td>\n",
       "      <td>0.343193</td>\n",
       "      <td>-0.039521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276802</td>\n",
       "      <td>0.291937</td>\n",
       "      <td>-0.037399</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>0.712719</td>\n",
       "      <td>-4.860838e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375955</td>\n",
       "      <td>0.687031</td>\n",
       "      <td>-0.021030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274257</td>\n",
       "      <td>0.343622</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276493</td>\n",
       "      <td>0.291918</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>0.711728</td>\n",
       "      <td>-4.852828e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.686995</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273890</td>\n",
       "      <td>0.341194</td>\n",
       "      <td>-0.037652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276375</td>\n",
       "      <td>0.288789</td>\n",
       "      <td>-0.035182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.301566</td>\n",
       "      <td>0.713592</td>\n",
       "      <td>-4.809959e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376861</td>\n",
       "      <td>0.686566</td>\n",
       "      <td>-0.019396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274778</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277258</td>\n",
       "      <td>0.290253</td>\n",
       "      <td>-0.034068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class        x1        y1            z1   v1        x2        y2  \\\n",
       "4854     Y  0.301277  0.713866 -4.999960e-07  0.0  0.376766  0.687557   \n",
       "4855     Y  0.300141  0.712820 -4.968692e-07  0.0  0.376357  0.686942   \n",
       "4856     Y  0.300001  0.712719 -4.860838e-07  0.0  0.375955  0.687031   \n",
       "4857     Y  0.300780  0.711728 -4.852828e-07  0.0  0.375800  0.686995   \n",
       "4858     Y  0.301566  0.713592 -4.809959e-07  0.0  0.376861  0.686566   \n",
       "\n",
       "            z2   v2        x3  ...       z19  v19       x20       y20  \\\n",
       "4854 -0.021483  0.0  0.443821  ... -0.037228  0.0  0.274309  0.341676   \n",
       "4855 -0.020894  0.0  0.444729  ... -0.035632  0.0  0.274595  0.343193   \n",
       "4856 -0.021030  0.0  0.444419  ... -0.035067  0.0  0.274257  0.343622   \n",
       "4857 -0.020841  0.0  0.444320  ... -0.034069  0.0  0.273890  0.341194   \n",
       "4858 -0.019396  0.0  0.444327  ... -0.033639  0.0  0.274778  0.342040   \n",
       "\n",
       "           z20  v20       x21       y21       z21  v21  \n",
       "4854 -0.039328  0.0  0.276596  0.289744 -0.035333  0.0  \n",
       "4855 -0.039521  0.0  0.276802  0.291937 -0.037399  0.0  \n",
       "4856 -0.039129  0.0  0.276493  0.291918 -0.037097  0.0  \n",
       "4857 -0.037652  0.0  0.276375  0.288789 -0.035182  0.0  \n",
       "4858 -0.036795  0.0  0.277258  0.290253 -0.034068  0.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757    T\n",
       "2783    O\n",
       "2181    L\n",
       "2697    O\n",
       "2963    P\n",
       "       ..\n",
       "4346    W\n",
       "2124    L\n",
       "495     C\n",
       "2231    L\n",
       "3066    P\n",
       "Name: class, Length: 1458, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Algor Lombako\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'C', 'F', 'F', 'A', 'C', 'F', 'B', 'A', 'D', 'F', 'D', 'C',\n",
       "       'A', 'B', 'D', 'D', 'H', 'D', 'E', 'D', 'D', 'E', 'C', 'H', 'A',\n",
       "       'H', 'E', 'F', 'B', 'D', 'D', 'D', 'D', 'E', 'F', 'B', 'D', 'B',\n",
       "       'C', 'H', 'C', 'A', 'A', 'D', 'C', 'A', 'D', 'A', 'E', 'G', 'D',\n",
       "       'H', 'A', 'H', 'C', 'G', 'G', 'A', 'B', 'D', 'B', 'D', 'A', 'G',\n",
       "       'A', 'H', 'D', 'A', 'G', 'C', 'E', 'G', 'A', 'C', 'A', 'D', 'D',\n",
       "       'G', 'D', 'E', 'E', 'A', 'D', 'H', 'F', 'C', 'D', 'D', 'E', 'A',\n",
       "       'A', 'C', 'F', 'G', 'D', 'H', 'H', 'B', 'H', 'C', 'A', 'F', 'F',\n",
       "       'H', 'E', 'A', 'B', 'B', 'B', 'D', 'F', 'B', 'C', 'C', 'C', 'F',\n",
       "       'D', 'F', 'G', 'F', 'A', 'D', 'B', 'G', 'A', 'D', 'E', 'A', 'D',\n",
       "       'D', 'G', 'F', 'D', 'A', 'F', 'F', 'G', 'G', 'F', 'H', 'G', 'H',\n",
       "       'B', 'G', 'B', 'B', 'H', 'G', 'B', 'C', 'C', 'D', 'F', 'A', 'D',\n",
       "       'C', 'A', 'C', 'F', 'F', 'B', 'G', 'D', 'H', 'H', 'B', 'D', 'D',\n",
       "       'A', 'A', 'F', 'A', 'A', 'C', 'A', 'E', 'H', 'G', 'A', 'C', 'C',\n",
       "       'B', 'C', 'C', 'C', 'H', 'D', 'F', 'C', 'B', 'A', 'E', 'B', 'C',\n",
       "       'G', 'C', 'B', 'F', 'E', 'G', 'D', 'F', 'A', 'B', 'C', 'B', 'H',\n",
       "       'G', 'F', 'D', 'A', 'E', 'B', 'G', 'E', 'H', 'A', 'A', 'B', 'H',\n",
       "       'A', 'B', 'B', 'F', 'H', 'F', 'G', 'C', 'G', 'A', 'G', 'A', 'A',\n",
       "       'F', 'B', 'A', 'D', 'E', 'F', 'F', 'D', 'D', 'D', 'B', 'D', 'F',\n",
       "       'D', 'B', 'G', 'D', 'D', 'D', 'D', 'A', 'C', 'D', 'D', 'D', 'A',\n",
       "       'C', 'D', 'A', 'C', 'H', 'F', 'G', 'A', 'F', 'A', 'E', 'A', 'D',\n",
       "       'F', 'F', 'B', 'D', 'D', 'F', 'G', 'F', 'D', 'H', 'B', 'H', 'B',\n",
       "       'A', 'C', 'A', 'B', 'C', 'A', 'G', 'D', 'B', 'A', 'B', 'A', 'D',\n",
       "       'F', 'D', 'G', 'D', 'B', 'G', 'D', 'D', 'D', 'D', 'A', 'F', 'A',\n",
       "       'B', 'F', 'C', 'A', 'B', 'E', 'B', 'F', 'D', 'E', 'D', 'B', 'A',\n",
       "       'B', 'D', 'H', 'B', 'F', 'A', 'F', 'B', 'C', 'C', 'H', 'A', 'C',\n",
       "       'A', 'G', 'F', 'A', 'C', 'C', 'E', 'D', 'F', 'A', 'H', 'H', 'D',\n",
       "       'B', 'F', 'H', 'B', 'E', 'A', 'E', 'A', 'C', 'F', 'G', 'E', 'F',\n",
       "       'E', 'F', 'A', 'B', 'A', 'D', 'G', 'D', 'D', 'B', 'A', 'D', 'F',\n",
       "       'E', 'C', 'A', 'H', 'C', 'E', 'C', 'F', 'D', 'D', 'H', 'E', 'B',\n",
       "       'A', 'E', 'B', 'F', 'F', 'F', 'F', 'A', 'A', 'F', 'A', 'A', 'A',\n",
       "       'F', 'B', 'A', 'A', 'A', 'H', 'H', 'G', 'B', 'A', 'E', 'B', 'F',\n",
       "       'E', 'A', 'B', 'H', 'H', 'D', 'C', 'G', 'A', 'H', 'A', 'C', 'A',\n",
       "       'C', 'H', 'D', 'C', 'A', 'G', 'F', 'A', 'B', 'B', 'G', 'A', 'C',\n",
       "       'H', 'H', 'B', 'G', 'C', 'G', 'A', 'H', 'F', 'C', 'G', 'F', 'F',\n",
       "       'A', 'F', 'A', 'E', 'A', 'G', 'E', 'H', 'A', 'H', 'F', 'E', 'F',\n",
       "       'F', 'A', 'H', 'D', 'F', 'G', 'C', 'A', 'H', 'E', 'B', 'D', 'B',\n",
       "       'A', 'B', 'D', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9890260631001372\n",
      "rc 0.9554183813443072\n",
      "rf 0.9945130315500685\n",
      "gb 0.9821673525377229\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'O', 'L', ..., 'C', 'L', 'P'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757    T\n",
       "2783    O\n",
       "2181    L\n",
       "2697    O\n",
       "2963    P\n",
       "       ..\n",
       "4346    W\n",
       "2124    L\n",
       "495     C\n",
       "2231    L\n",
       "3066    P\n",
       "Name: class, Length: 1458, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Initiate holistic model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_holistic\u001b[38;5;241m.\u001b[39mHolistic(min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m holistic:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "         #                        mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "          #                       mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                #                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "         #                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "          #                       mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "           #                      )\n",
    "\n",
    "        if results.right_hand_landmarks:\n",
    "            pose = results.right_hand_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            row = pose_row\n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            #print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(' '):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
